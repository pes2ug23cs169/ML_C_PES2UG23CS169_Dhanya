{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Customer Segmentation Analysis - Student Exercise\n",
    "\n",
    "In this lab, you will implement customer segmentation using K-means clustering. You'll learn how to:\n",
    "1. Preprocess data for clustering\n",
    "2. Perform and visualize dimensionality reduction\n",
    "3. Implement K-means clustering from scratch\n",
    "4. Evaluate clustering results\n",
    "\n",
    "Follow the instructions in each section and fill in the code where indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Preprocess\n",
    "def load_data(filepath):\n",
    "    pass\n",
    "\n",
    "#================ FOR PCA Dimensionality reduction =========\n",
    "# Apply PCA for Dimensionality Reduction\n",
    "def apply_pca(x, n_components):\n",
    "    pass\n",
    "\n",
    "#================ FOR K-Means ===============================\n",
    "# Find Optimal Clusters for KMeans (Elbow Method) \n",
    "def find_optimal_clusters(x, max_clusters=10):\n",
    "    pass\n",
    "\n",
    "# Perform KMeans Clustering \n",
    "# Change None to the number of n_clusters value from the elbow method\n",
    "def perform_kmeans_clustering(x, n_clusters=None):\n",
    "    pass\n",
    "\n",
    "#================ FOR Agglomerative ===============================\n",
    "# Perform Agglomerative Clustering \n",
    "# Change None to the number of n_clusters value from the elbow method\n",
    "def perform_agglomerative_clustering(x, n_clusters=None):\n",
    "    pass\n",
    "\n",
    "#================FOR Dendrogram===============================\n",
    "# Get Linkages for Dendrogram\n",
    "def get_linkages(x):\n",
    "    pass\n",
    "\n",
    "# Plot Dendrogram\n",
    "def plot_dendrogram(linked):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "First, complete the data preprocessing function below. You need to:\n",
    "1. Load the data\n",
    "2. Handle categorical variables\n",
    "3. Scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"Load and preprocess the bank marketing dataset.\n",
    "    \n",
    "    TODO:\n",
    "    1. Load the CSV file (hint: it uses semicolon separator)\n",
    "    2. Convert categorical columns to numerical using LabelEncoder\n",
    "    3. Scale the features using StandardScaler\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    # Load data\n",
    "    df = # TODO: Load CSV with correct separator\n",
    "    \n",
    "    # List of categorical columns to encode\n",
    "    categorical_cols = ['job', 'marital', 'education', 'default', 'housing', \n",
    "                       'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "    \n",
    "    # TODO: Apply label encoding to categorical columns\n",
    "    \n",
    "    # Select features for clustering\n",
    "    features = ['age', 'balance', 'campaign', 'previous', 'job', 'education', \n",
    "               'housing', 'loan', 'default']\n",
    "    X = # TODO: Select features\n",
    "    \n",
    "    # TODO: Scale the features\n",
    "    X_scaled = # TODO: Apply StandardScaler\n",
    "    \n",
    "    return X_scaled, df\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_scaled, data = load_data('bank-full.csv')\n",
    "print(\"Data shape:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClustering:\n",
    "    \"\"\"Minimal K-means skeleton for students to implement.\n",
    "\n",
    "    Students should implement the core methods below:\n",
    "    - _initialize_centroids\n",
    "    - _assign_clusters\n",
    "    - _update_centroids\n",
    "    - fit\n",
    "\n",
    "    Keep implementations simple and readable; tests and visualization code will\n",
    "    use these methods once implemented.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=3, max_iters=100, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "        self.random_state = random_state\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "\n",
    "    def _initialize_centroids(self, X):\n",
    "        \"\"\"Initialize centroids.\n",
    "\n",
    "        TODO (student):\n",
    "        - Randomly select `n_clusters` distinct points from X as initial centroids.\n",
    "        - Return an array of shape (n_clusters, n_features).\n",
    "        Hint: Use np.random.choice to pick indices.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"_initialize_centroids must be implemented by the student\")\n",
    "\n",
    "    def _assign_clusters(self, X):\n",
    "        \"\"\"Assign each sample in X to the nearest centroid.\n",
    "\n",
    "        TODO (student):\n",
    "        - Compute distance from each point to each centroid (Euclidean)\n",
    "        - Return an integer array of shape (n_samples,) with cluster labels\n",
    "        Hint: np.linalg.norm with axis manipulation or broadcasting helps here.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"_assign_clusters must be implemented by the student\")\n",
    "\n",
    "    def _update_centroids(self, X, labels):\n",
    "        \"\"\"Recompute centroids as the mean of points assigned to each cluster.\n",
    "\n",
    "        TODO (student):\n",
    "        - For each cluster id in 0..n_clusters-1 compute the mean of points\n",
    "          assigned to that cluster. If a cluster has no points, consider reinitializing\n",
    "          its centroid (or leave unchanged) â€” discuss in your report.\n",
    "        - Return an array of shape (n_clusters, n_features).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"_update_centroids must be implemented by the student\")\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Run K-means until convergence or max_iters.\n",
    "\n",
    "        TODO (student):\n",
    "        - Initialize centroids\n",
    "        - Loop: assign clusters, update centroids\n",
    "        - Stop early if centroids do not change (or change below a tiny threshold)\n",
    "        - Store final labels in self.labels and centroids in self.centroids\n",
    "        - Return self\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"fit must be implemented by the student\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Assign cluster labels to X using the learned centroids.\n",
    "\n",
    "        Implementation may call _assign_clusters but should error if centroids\n",
    "        are not yet initialized (i.e., if fit wasn't called).\n",
    "        \"\"\"\n",
    "        if self.centroids is None:\n",
    "            raise ValueError(\"Model has not been fitted yet. Call fit(X) first.\")\n",
    "        return self._assign_clusters(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimensionality Reduction\n",
    "\n",
    "Before clustering, we often reduce the dimensionality of our data for better visualization and performance. Implement PCA below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X, n_components=2):\n",
    "    \"\"\"Apply PCA for dimensionality reduction.\n",
    "    \n",
    "    TODO:\n",
    "    1. Initialize and fit PCA\n",
    "    2. Transform the data\n",
    "    3. Create visualizations to understand:\n",
    "       - Explained variance ratio\n",
    "       - Cumulative explained variance\n",
    "       - Data distribution in 2D\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # TODO: Create visualization\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot explained variance\n",
    "    # Your code here\n",
    "    \n",
    "    # Plot data in 2D\n",
    "    # Your code here\n",
    "    \n",
    "    return X_pca\n",
    "\n",
    "# Apply PCA\n",
    "X_pca = apply_pca(X_scaled)\n",
    "print(\"Shape after PCA:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering Evaluation\n",
    "\n",
    "Implement functions to evaluate the quality of your clustering results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inertia(X, labels, centroids):\n",
    "    \"\"\"Calculate the within-cluster sum of squares (inertia).\n",
    "    \n",
    "    TODO:\n",
    "    1. For each cluster, calculate the sum of squared distances\n",
    "       between points and their centroid\n",
    "    2. Sum up all cluster distances\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    inertia = 0\n",
    "    # Calculate distances between points and their assigned centroids\n",
    "    return inertia\n",
    "\n",
    "def plot_elbow_curve(X, max_k=10):\n",
    "    \"\"\"Plot the elbow curve to find optimal number of clusters.\n",
    "    \n",
    "    TODO:\n",
    "    1. Try different values of k (1 to max_k)\n",
    "    2. Calculate inertia for each k\n",
    "    3. Plot k vs inertia\n",
    "    4. Help identify the 'elbow' point\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    inertias = []\n",
    "    K = range(1, max_k + 1)\n",
    "    \n",
    "    # Calculate inertia for different k values\n",
    "    # Your code here\n",
    "    \n",
    "    # Create elbow plot\n",
    "    # Your code here\n",
    "    \n",
    "    return inertias\n",
    "\n",
    "# Try different numbers of clusters\n",
    "inertias = plot_elbow_curve(X_pca)\n",
    "\n",
    "# Apply final clustering\n",
    "kmeans = KMeansClustering(n_clusters=3)  # Try different values based on elbow curve\n",
    "kmeans.fit(X_pca)\n",
    "\n",
    "# Visualize final results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot clusters\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans.labels, cmap='viridis')\n",
    "plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1], \n",
    "            c='red', marker='x', s=200, label='Centroids')\n",
    "plt.title('Final Clustering Results')\n",
    "plt.legend()\n",
    "\n",
    "# Plot evaluation metrics\n",
    "plt.subplot(1, 2, 2)\n",
    "# Your code here: Add relevant evaluation metric plots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "inertia = calculate_inertia(X_pca, kmeans.labels, kmeans.centroids)\n",
    "silhouette = silhouette_score(X_pca, kmeans.labels)\n",
    "\n",
    "print(\"\\nClustering Evaluation:\")\n",
    "print(f\"Inertia: {inertia:.2f}\")\n",
    "print(f\"Silhouette Score: {silhouette:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recursive Bisecting K-means (Student exercise)\n",
    "\n",
    "This is an optional exercise for students who want to explore a hierarchical variant of K-means.\n",
    "\n",
    "Task: implement a concise bisecting K-means procedure that recursively splits clusters into two until a target number of clusters is reached.\n",
    "\n",
    "Learning goals:\n",
    "- Understand how repeated binary splits can form a hierarchical clustering\n",
    "- Practice applying K-means on subclusters and tracking labels/centroids\n",
    "\n",
    "Hints:\n",
    "- You can use sklearn's KMeans(k=2) for the binary split step, or reuse your `KMeansClustering` implementation.\n",
    "- Keep label bookkeeping simple: use increasing integer labels for new clusters.\n",
    "- Store split metadata (parent -> left/right) to enable a tree visualization later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BisectingKMeans:\n",
    "    \"\"\"Concise skeleton for students to implement a bisecting K-means algorithm.\n",
    "\n",
    "    Students should implement `fit_predict` to recursively split clusters until\n",
    "    `n_clusters` is reached.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.labels_ = None\n",
    "        # Optional: store mapping parent -> (left_label, right_label)\n",
    "        self.split_tree = {}\n",
    "        # Optional: store centroids per cluster id\n",
    "        self.centers_ = {}\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"Recursively bisect clusters until `n_clusters` is reached.\n",
    "\n",
    "        TODO (student):\n",
    "        - Start with all points assigned to label 0.\n",
    "        - While number of unique labels < n_clusters:\n",
    "            - Select a cluster to split (e.g., the largest cluster by size)\n",
    "            - Run a binary KMeans (k=2) on the points in that cluster\n",
    "            - Assign new labels (keep one child label as the original, give the other a new id)\n",
    "            - Record parent -> (left, right) in `self.split_tree` and centroids in `self.centers_`\n",
    "        - Set and return `self.labels_` (numpy array of length n_samples)\n",
    "\n",
    "        Hints:\n",
    "        - Use sklearn.cluster.KMeans(n_clusters=2, random_state=self.random_state) for the split step\n",
    "        - Keep a counter for new label ids and increment when creating a new cluster\n",
    "        - Use boolean indexing to operate on subsets of X efficiently\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Implement the bisecting algorithm as a student exercise')\n",
    "\n",
    "# Example (for instructor use only):\n",
    "# bisect = BisectingKMeans(n_clusters=4)\n",
    "# labels = bisect.fit_predict(X_pca)\n",
    "# plt.scatter(X_pca[:,0], X_pca[:,1], c=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenges\n",
    "\n",
    "If you've completed the main tasks, try these extensions:\n",
    "\n",
    "1. Implement k-means++ initialization\n",
    "   - Instead of random initialization, use the k-means++ algorithm\n",
    "   - This should give better and more consistent results\n",
    "\n",
    "2. Add cluster interpretation\n",
    "   - Analyze the characteristics of each cluster\n",
    "   - What features distinguish one cluster from another?\n",
    "   - Create visualizations to show cluster properties\n",
    "\n",
    "3. Try different distance metrics\n",
    "   - Implement Manhattan distance instead of Euclidean\n",
    "   - Compare the clustering results\n",
    "\n",
    "4. Add outlier detection\n",
    "   - Identify points far from all centroids\n",
    "   - How might you handle these outliers?\n",
    "\n",
    "Remember to document your code and explain your findings!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
