{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t5ZD8IEVhS9",
        "outputId": "481060b9-9470-421f-f7cf-6361804e705e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hAll imports done!\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets -q\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import pickle\n",
        "from typing import List, Set, Tuple, Dict\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"All imports done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jjxtaK8HVwSM"
      },
      "outputs": [],
      "source": [
        "# CELL 2: Hidden Markov Model (HMM)\n",
        "class HangmanHMM:\n",
        "    def __init__(self, max_length=20):\n",
        "        self.max_length = max_length\n",
        "        self.emission_probs = {}\n",
        "        self.transition_probs = {}\n",
        "        self.initial_probs = {}\n",
        "        self.letter_freq = Counter()\n",
        "\n",
        "    def train(self, word_list: List[str]):\n",
        "        print(\"Training HMM...\")\n",
        "        words_by_length = defaultdict(list)\n",
        "        for word in word_list:\n",
        "            word = word.lower().strip()\n",
        "            if word.isalpha():\n",
        "                words_by_length[len(word)].append(word)\n",
        "                for char in word:\n",
        "                    self.letter_freq[char] += 1\n",
        "\n",
        "        for length, words in words_by_length.items():\n",
        "            if length > self.max_length or length == 0:\n",
        "                continue\n",
        "            self.emission_probs[length] = {}\n",
        "            self.transition_probs[length] = {}\n",
        "\n",
        "            emission_counts = {pos: Counter() for pos in range(length)}\n",
        "            initial_counts = Counter()\n",
        "            transition_counts = {pos: {} for pos in range(1, length)}\n",
        "\n",
        "            for word in words:\n",
        "                for pos, char in enumerate(word):\n",
        "                    emission_counts[pos][char] += 1\n",
        "                    if pos == 0:\n",
        "                        initial_counts[char] += 1\n",
        "                    else:\n",
        "                        prev = word[pos-1]\n",
        "                        if prev not in transition_counts[pos]:\n",
        "                            transition_counts[pos][prev] = Counter()\n",
        "                        transition_counts[pos][prev][char] += 1\n",
        "\n",
        "            # Emission probs\n",
        "            for pos in range(length):\n",
        "                total = sum(emission_counts[pos].values())\n",
        "                self.emission_probs[length][pos] = {\n",
        "                    c: (emission_counts[pos].get(c, 0) + 1) / (total + 26)\n",
        "                    for c in 'abcdefghijklmnopqrstuvwxyz'\n",
        "                }\n",
        "\n",
        "            # Transition probs\n",
        "            for pos in range(1, length):\n",
        "                self.transition_probs[length][pos] = {}\n",
        "                for prev in 'abcdefghijklmnopqrstuvwxyz':\n",
        "                    if prev in transition_counts[pos]:\n",
        "                        tot = sum(transition_counts[pos][prev].values())\n",
        "                        self.transition_probs[length][pos][prev] = {\n",
        "                            c: (transition_counts[pos][prev].get(c, 0) + 1) / (tot + 26)\n",
        "                            for c in 'abcdefghijklmnopqrstuvwxyz'\n",
        "                        }\n",
        "                    else:\n",
        "                        self.transition_probs[length][pos][prev] = {c: 1/26 for c in 'abcdefghijklmnopqrstuvwxyz'}\n",
        "\n",
        "            # Initial probs\n",
        "            tot_init = sum(initial_counts.values())\n",
        "            self.initial_probs[length] = {\n",
        "                c: (initial_counts.get(c, 0) + 1) / (tot_init + 26)\n",
        "                for c in 'abcdefghijklmnopqrstuvwxyz'\n",
        "            }\n",
        "\n",
        "        print(f\"HMM trained on {len(word_list)} words\")\n",
        "\n",
        "    def predict_letter_probs(self, masked_word: str, guessed_letters: Set[str]) -> Dict[str, float]:\n",
        "        length = len(masked_word)\n",
        "        scores = defaultdict(float)\n",
        "\n",
        "        if length not in self.emission_probs:\n",
        "            total = sum(self.letter_freq.values()) or 1\n",
        "            for c in 'abcdefghijklmnopqrstuvwxyz':\n",
        "                if c not in guessed_letters:\n",
        "                    scores[c] = self.letter_freq.get(c, 1) / total\n",
        "            return dict(scores)\n",
        "\n",
        "        for pos, ch in enumerate(masked_word):\n",
        "            if ch != '_':\n",
        "                continue\n",
        "            for let in 'abcdefghijklmnopqrstuvwxyz':\n",
        "                if let in guessed_letters:\n",
        "                    continue\n",
        "                scores[let] += self.emission_probs[length][pos].get(let, 1/26)\n",
        "\n",
        "            if pos > 0 and masked_word[pos-1] != '_':\n",
        "                prev = masked_word[pos-1]\n",
        "                if prev in self.transition_probs[length][pos]:\n",
        "                    for let in 'abcdefghijklmnopqrstuvwxyz':\n",
        "                        if let not in guessed_letters:\n",
        "                            scores[let] += self.transition_probs[length][pos][prev].get(let, 1/26) * 1.5\n",
        "\n",
        "        total = sum(scores.values())\n",
        "        if total > 0:\n",
        "            scores = {k: v/total for k, v in scores.items()}\n",
        "        else:\n",
        "            remaining = [c for c in 'abcdefghijklmnopqrstuvwxyz' if c not in guessed_letters]\n",
        "            scores = {c: 1/len(remaining) for c in remaining}\n",
        "        return dict(scores)\n",
        "\n",
        "    def save(self, path):\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'emission': self.emission_probs,\n",
        "                'transition': self.transition_probs,\n",
        "                'initial': self.initial_probs,\n",
        "                'freq': self.letter_freq,\n",
        "                'max_len': self.max_length\n",
        "            }, f)\n",
        "        print(f\"HMM saved to {path}\")\n",
        "\n",
        "    def load(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.emission_probs = data['emission']\n",
        "            self.transition_probs = data['transition']\n",
        "            self.initial_probs = data['initial']\n",
        "            self.letter_freq = data['freq']\n",
        "            self.max_length = data['max_len']\n",
        "        print(f\"HMM loaded from {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zoqUDIptVztN"
      },
      "outputs": [],
      "source": [
        "# CELL 3: Hangman Environment\n",
        "class HangmanEnvironment:\n",
        "    def __init__(self, word: str, max_wrong: int = 6):\n",
        "        self.word = word.lower()\n",
        "        self.max_wrong = max_wrong\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.guessed = set()\n",
        "        self.wrong = 0\n",
        "        self.repeated = 0\n",
        "        self.over = False\n",
        "        self.won = False\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        masked = ''.join(c if c in self.guessed else '_' for c in self.word)\n",
        "        return {\n",
        "            'masked_word': masked,\n",
        "            'guessed_letters': self.guessed.copy(),\n",
        "            'wrong_guesses': self.wrong,\n",
        "            'lives_remaining': self.max_wrong - self.wrong,\n",
        "            'game_over': self.over,\n",
        "            'won': self.won,\n",
        "            'word_length': len(self.word)\n",
        "        }\n",
        "\n",
        "    def step(self, letter: str):\n",
        "        letter = letter.lower()\n",
        "        if letter in self.guessed:\n",
        "            self.repeated += 1\n",
        "            return self.get_state(), -2, self.over\n",
        "\n",
        "        self.guessed.add(letter)\n",
        "        if letter in self.word:\n",
        "            occ = self.word.count(letter)\n",
        "            reward = 1 * occ\n",
        "            if all(c in self.guessed for c in self.word):\n",
        "                self.won = True\n",
        "                self.over = True\n",
        "                reward += 20\n",
        "        else:\n",
        "            self.wrong += 1\n",
        "            reward = -5\n",
        "            if self.wrong >= self.max_wrong:\n",
        "                self.over = True\n",
        "                reward -= 10\n",
        "        return self.get_state(), reward, self.over\n",
        "\n",
        "    def get_available_actions(self):\n",
        "        return [c for c in 'abcdefghijklmnopqrstuvwxyz' if c not in self.guessed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3FTBHGqvV31g"
      },
      "outputs": [],
      "source": [
        "# CELL 4: State Encoder\n",
        "class StateEncoder:\n",
        "    def encode(self, state: Dict, hmm_probs: Dict[str, float]) -> np.ndarray:\n",
        "        features = []\n",
        "        masked = state['masked_word']\n",
        "        length = state['word_length']\n",
        "\n",
        "        revealed = sum(1 for c in masked if c != '_')\n",
        "        features.append(revealed / length if length > 0 else 0)\n",
        "        features.append(state['lives_remaining'] / 6.0)\n",
        "        features.append(len(state['guessed_letters']) / 26.0)\n",
        "        features.append(length / 20.0)\n",
        "\n",
        "        vowels = sum(1 for c in masked if c in 'aeiou')\n",
        "        consonants = revealed - vowels\n",
        "        features.append(vowels / length if length > 0 else 0)\n",
        "        features.append(consonants / length if length > 0 else 0)\n",
        "        features.append(masked.count('_') / length if length > 0 else 0)\n",
        "\n",
        "        for c in 'abcdefghijklmnopqrstuvwxyz':\n",
        "            features.append(hmm_probs.get(c, 0.0))\n",
        "\n",
        "        return np.array(features, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eYlISbrQV6Gj"
      },
      "outputs": [],
      "source": [
        "# CELL 5: Q-Learning Agent (FULL signature)\n",
        "class HangmanQLearningAgent:\n",
        "    def __init__(self,\n",
        "                 hmm,\n",
        "                 learning_rate: float = 0.01,\n",
        "                 discount_factor: float = 0.95,\n",
        "                 epsilon_start: float = 1.0,\n",
        "                 epsilon_end: float = 0.01,\n",
        "                 epsilon_decay: float = 0.995):\n",
        "        self.hmm = hmm\n",
        "        self.encoder = StateEncoder()\n",
        "        self.lr = learning_rate\n",
        "        self.gamma = discount_factor\n",
        "        self.epsilon = epsilon_start\n",
        "        self.epsilon_end = epsilon_end\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "\n",
        "        # one weight vector per letter (lazy-init)\n",
        "        self.weights = {c: None for c in 'abcdefghijklmnopqrstuvwxyz'}\n",
        "\n",
        "        # training stats\n",
        "        self.stats = {'episodes': 0, 'wins': 0, 'total_reward': 0.0}\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Helper: initialise weights when first needed\n",
        "    # -------------------------------------------------\n",
        "    def _init_weights(self, size: int):\n",
        "        for c in 'abcdefghijklmnopqrstuvwxyz':\n",
        "            if self.weights[c] is None:\n",
        "                self.weights[c] = np.random.randn(size) * 0.01\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Q-value\n",
        "    # -------------------------------------------------\n",
        "    def get_q(self, features: np.ndarray, action: str) -> float:\n",
        "        if self.weights[action] is None:\n",
        "            self._init_weights(len(features))\n",
        "        return np.dot(self.weights[action], features)\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Action selection (epsilon-greedy + HMM boost)\n",
        "    # -------------------------------------------------\n",
        "    def choose_action(self, state: Dict, actions: List[str], training: bool = True) -> str:\n",
        "        hmm_probs = self.hmm.predict_letter_probs(state['masked_word'], state['guessed_letters'])\n",
        "        feats = self.encoder.encode(state, hmm_probs)\n",
        "\n",
        "        if training and random.random() < self.epsilon:\n",
        "            # explore with HMM probabilities\n",
        "            probs = [hmm_probs.get(a, 1e-6) for a in actions]\n",
        "            total = sum(probs)\n",
        "            probs = [p/total for p in probs]\n",
        "            return np.random.choice(actions, p=probs)\n",
        "        else:\n",
        "            # exploit\n",
        "            vals = {}\n",
        "            for a in actions:\n",
        "                q = self.get_q(feats, a)\n",
        "                boost = hmm_probs.get(a, 0) * 2.0\n",
        "                vals[a] = q + boost\n",
        "            return max(vals.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # TD update\n",
        "    # -------------------------------------------------\n",
        "    def update(self, state: Dict, action: str, reward: float,\n",
        "               next_state: Dict, done: bool):\n",
        "        hmm_probs = self.hmm.predict_letter_probs(state['masked_word'], state['guessed_letters'])\n",
        "        feats = self.encoder.encode(state, hmm_probs)\n",
        "        q_curr = self.get_q(feats, action)\n",
        "\n",
        "        if done:\n",
        "            q_target = reward\n",
        "        else:\n",
        "            next_hmm = self.hmm.predict_letter_probs(\n",
        "                next_state['masked_word'], next_state['guessed_letters'])\n",
        "            next_feats = self.encoder.encode(next_state, next_hmm)\n",
        "            next_actions = [c for c in 'abcdefghijklmnopqrstuvwxyz'\n",
        "                           if c not in next_state['guessed_letters']]\n",
        "            max_q = max(self.get_q(next_feats, a) for a in next_actions) if next_actions else 0.0\n",
        "            q_target = reward + self.gamma * max_q\n",
        "\n",
        "        td_error = q_target - q_curr\n",
        "        self.weights[action] += self.lr * td_error * feats\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Epsilon decay\n",
        "    # -------------------------------------------------\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_end, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # One training episode\n",
        "    # -------------------------------------------------\n",
        "    def train_episode(self, word: str) -> Dict:\n",
        "        env = HangmanEnvironment(word)\n",
        "        state = env.reset()\n",
        "        total_r = 0.0\n",
        "\n",
        "        while not state['game_over']:\n",
        "            actions = env.get_available_actions()\n",
        "            action = self.choose_action(state, actions, training=True)\n",
        "            next_state, r, done = env.step(action)\n",
        "            self.update(state, action, r, next_state, done)\n",
        "            total_r += r\n",
        "            state = next_state\n",
        "\n",
        "        self.stats['episodes'] += 1\n",
        "        self.stats['total_reward'] += total_r\n",
        "        if state['won']:\n",
        "            self.stats['wins'] += 1\n",
        "\n",
        "        self.decay_epsilon()\n",
        "        return {'won': state['won'], 'reward': total_r}\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Play (no training)\n",
        "    # -------------------------------------------------\n",
        "    def play(self, word: str) -> Dict:\n",
        "        env = HangmanEnvironment(word)\n",
        "        state = env.reset()\n",
        "        while not state['game_over']:\n",
        "            actions = env.get_available_actions()\n",
        "            action = self.choose_action(state, actions, training=False)\n",
        "            state, _, _ = env.step(action)\n",
        "        return {\n",
        "            'won': state['won'],\n",
        "            'word': word,\n",
        "            'wrong': state['wrong_guesses']\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Save / Load\n",
        "    # -------------------------------------------------\n",
        "    def save(self, path: str):\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'weights': self.weights,\n",
        "                'stats': self.stats,\n",
        "                'epsilon': self.epsilon\n",
        "            }, f)\n",
        "        print(f\"Agent saved → {path}\")\n",
        "\n",
        "    def load(self, path: str):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.weights = data['weights']\n",
        "            self.stats = data['stats']\n",
        "            self.epsilon = data.get('epsilon', self.epsilon_end)\n",
        "        print(f\"Agent loaded ← {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "eIv3JmF6V8by",
        "outputId": "23356c03-4534-4f00-8cc3-06e9ed05975a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please upload your 'corpus.txt' and 'test.txt' files:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c21041ad-ea03-4f63-816a-252caa225dca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c21041ad-ea03-4f63-816a-252caa225dca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving test.txt to test.txt\n",
            "Saving corpus.txt to corpus.txt\n",
            "Loaded 49979 words from corpus.txt\n",
            "Loaded 2000 words from test.txt\n",
            "Your real datasets are ready for training!\n"
          ]
        }
      ],
      "source": [
        "# CELL 6: Upload Your Real Datasets\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"Please upload your 'corpus.txt' and 'test.txt' files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verify and load\n",
        "def load_words_from_uploaded(name):\n",
        "    if name not in uploaded:\n",
        "        raise FileNotFoundError(f\"{name} not uploaded!\")\n",
        "    content = uploaded[name].decode('utf-8')\n",
        "    words = [line.strip().lower() for line in content.splitlines() if line.strip() and line.strip().isalpha()]\n",
        "    print(f\"Loaded {len(words)} words from {name}\")\n",
        "    return words\n",
        "\n",
        "# Load both\n",
        "train_words = load_words_from_uploaded(\"corpus.txt\")\n",
        "test_words = load_words_from_uploaded(\"test.txt\")\n",
        "\n",
        "# Save to disk so later cells can read them (required for training)\n",
        "with open(\"corpus.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(train_words))\n",
        "with open(\"test.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(test_words))\n",
        "\n",
        "print(\"Your real datasets are ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYJVn9WdWVEm",
        "outputId": "73d62340-2f4f-4509-9c87-bae4e2f60c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading your corpus...\n",
            "Training HMM on 49979 words...\n",
            "Training HMM...\n",
            "HMM trained on 49979 words\n",
            "HMM saved to hangman_hmm.pkl\n",
            "Initializing Q-Learning Agent...\n",
            "Starting training (10,000 episodes)...\n",
            "Episode 1000/100000 | Win Rate: 13.80% | Avg Reward: -27.93 | ε: 0.010\n",
            "Episode 2000/100000 | Win Rate: 18.05% | Avg Reward: -25.64 | ε: 0.010\n",
            "Episode 3000/100000 | Win Rate: 20.27% | Avg Reward: -24.52 | ε: 0.010\n",
            "Episode 4000/100000 | Win Rate: 20.88% | Avg Reward: -24.22 | ε: 0.010\n",
            "Episode 5000/100000 | Win Rate: 21.66% | Avg Reward: -23.81 | ε: 0.010\n",
            "Episode 6000/100000 | Win Rate: 22.17% | Avg Reward: -23.51 | ε: 0.010\n",
            "Episode 7000/100000 | Win Rate: 22.83% | Avg Reward: -23.18 | ε: 0.010\n",
            "Episode 8000/100000 | Win Rate: 23.15% | Avg Reward: -22.98 | ε: 0.010\n",
            "Episode 9000/100000 | Win Rate: 23.66% | Avg Reward: -22.72 | ε: 0.010\n",
            "Episode 10000/100000 | Win Rate: 24.13% | Avg Reward: -22.47 | ε: 0.010\n",
            "Episode 11000/100000 | Win Rate: 24.35% | Avg Reward: -22.36 | ε: 0.010\n",
            "Episode 12000/100000 | Win Rate: 24.71% | Avg Reward: -22.19 | ε: 0.010\n",
            "Episode 13000/100000 | Win Rate: 24.79% | Avg Reward: -22.12 | ε: 0.010\n",
            "Episode 14000/100000 | Win Rate: 24.79% | Avg Reward: -22.11 | ε: 0.010\n",
            "Episode 15000/100000 | Win Rate: 25.09% | Avg Reward: -21.97 | ε: 0.010\n",
            "Episode 16000/100000 | Win Rate: 25.26% | Avg Reward: -21.89 | ε: 0.010\n",
            "Episode 17000/100000 | Win Rate: 25.42% | Avg Reward: -21.82 | ε: 0.010\n",
            "Episode 18000/100000 | Win Rate: 25.52% | Avg Reward: -21.78 | ε: 0.010\n",
            "Episode 19000/100000 | Win Rate: 25.67% | Avg Reward: -21.69 | ε: 0.010\n",
            "Episode 20000/100000 | Win Rate: 25.74% | Avg Reward: -21.66 | ε: 0.010\n",
            "Episode 21000/100000 | Win Rate: 25.89% | Avg Reward: -21.58 | ε: 0.010\n",
            "Episode 22000/100000 | Win Rate: 25.90% | Avg Reward: -21.58 | ε: 0.010\n",
            "Episode 23000/100000 | Win Rate: 25.96% | Avg Reward: -21.55 | ε: 0.010\n",
            "Episode 24000/100000 | Win Rate: 25.96% | Avg Reward: -21.55 | ε: 0.010\n",
            "Episode 25000/100000 | Win Rate: 26.10% | Avg Reward: -21.49 | ε: 0.010\n",
            "Episode 26000/100000 | Win Rate: 26.22% | Avg Reward: -21.43 | ε: 0.010\n",
            "Episode 27000/100000 | Win Rate: 26.33% | Avg Reward: -21.38 | ε: 0.010\n",
            "Episode 28000/100000 | Win Rate: 26.45% | Avg Reward: -21.32 | ε: 0.010\n",
            "Episode 29000/100000 | Win Rate: 26.54% | Avg Reward: -21.27 | ε: 0.010\n",
            "Episode 30000/100000 | Win Rate: 26.73% | Avg Reward: -21.18 | ε: 0.010\n",
            "Episode 31000/100000 | Win Rate: 26.77% | Avg Reward: -21.15 | ε: 0.010\n",
            "Episode 32000/100000 | Win Rate: 26.82% | Avg Reward: -21.12 | ε: 0.010\n",
            "Episode 33000/100000 | Win Rate: 26.85% | Avg Reward: -21.11 | ε: 0.010\n",
            "Episode 34000/100000 | Win Rate: 26.91% | Avg Reward: -21.08 | ε: 0.010\n",
            "Episode 35000/100000 | Win Rate: 26.93% | Avg Reward: -21.06 | ε: 0.010\n",
            "Episode 36000/100000 | Win Rate: 26.92% | Avg Reward: -21.07 | ε: 0.010\n",
            "Episode 37000/100000 | Win Rate: 26.91% | Avg Reward: -21.07 | ε: 0.010\n",
            "Episode 38000/100000 | Win Rate: 26.95% | Avg Reward: -21.05 | ε: 0.010\n",
            "Episode 39000/100000 | Win Rate: 27.04% | Avg Reward: -21.00 | ε: 0.010\n",
            "Episode 40000/100000 | Win Rate: 27.06% | Avg Reward: -20.99 | ε: 0.010\n",
            "Episode 41000/100000 | Win Rate: 27.12% | Avg Reward: -20.96 | ε: 0.010\n",
            "Episode 42000/100000 | Win Rate: 27.16% | Avg Reward: -20.95 | ε: 0.010\n",
            "Episode 43000/100000 | Win Rate: 27.24% | Avg Reward: -20.90 | ε: 0.010\n",
            "Episode 44000/100000 | Win Rate: 27.35% | Avg Reward: -20.85 | ε: 0.010\n",
            "Episode 45000/100000 | Win Rate: 27.38% | Avg Reward: -20.83 | ε: 0.010\n",
            "Episode 46000/100000 | Win Rate: 27.46% | Avg Reward: -20.79 | ε: 0.010\n",
            "Episode 47000/100000 | Win Rate: 27.46% | Avg Reward: -20.78 | ε: 0.010\n",
            "Episode 48000/100000 | Win Rate: 27.44% | Avg Reward: -20.79 | ε: 0.010\n",
            "Episode 49000/100000 | Win Rate: 27.44% | Avg Reward: -20.79 | ε: 0.010\n",
            "Episode 50000/100000 | Win Rate: 27.53% | Avg Reward: -20.74 | ε: 0.010\n",
            "Episode 51000/100000 | Win Rate: 27.55% | Avg Reward: -20.73 | ε: 0.010\n",
            "Episode 52000/100000 | Win Rate: 27.56% | Avg Reward: -20.71 | ε: 0.010\n",
            "Episode 53000/100000 | Win Rate: 27.62% | Avg Reward: -20.69 | ε: 0.010\n",
            "Episode 54000/100000 | Win Rate: 27.63% | Avg Reward: -20.68 | ε: 0.010\n",
            "Episode 55000/100000 | Win Rate: 27.68% | Avg Reward: -20.65 | ε: 0.010\n",
            "Episode 56000/100000 | Win Rate: 27.70% | Avg Reward: -20.64 | ε: 0.010\n",
            "Episode 57000/100000 | Win Rate: 27.70% | Avg Reward: -20.63 | ε: 0.010\n",
            "Episode 58000/100000 | Win Rate: 27.72% | Avg Reward: -20.62 | ε: 0.010\n",
            "Episode 59000/100000 | Win Rate: 27.77% | Avg Reward: -20.60 | ε: 0.010\n",
            "Episode 60000/100000 | Win Rate: 27.82% | Avg Reward: -20.58 | ε: 0.010\n",
            "Episode 61000/100000 | Win Rate: 27.89% | Avg Reward: -20.55 | ε: 0.010\n",
            "Episode 62000/100000 | Win Rate: 27.98% | Avg Reward: -20.51 | ε: 0.010\n",
            "Episode 63000/100000 | Win Rate: 27.99% | Avg Reward: -20.50 | ε: 0.010\n",
            "Episode 64000/100000 | Win Rate: 28.00% | Avg Reward: -20.50 | ε: 0.010\n",
            "Episode 65000/100000 | Win Rate: 27.99% | Avg Reward: -20.50 | ε: 0.010\n",
            "Episode 66000/100000 | Win Rate: 28.01% | Avg Reward: -20.50 | ε: 0.010\n",
            "Episode 67000/100000 | Win Rate: 28.03% | Avg Reward: -20.49 | ε: 0.010\n",
            "Episode 68000/100000 | Win Rate: 28.09% | Avg Reward: -20.46 | ε: 0.010\n",
            "Episode 69000/100000 | Win Rate: 28.11% | Avg Reward: -20.45 | ε: 0.010\n",
            "Episode 70000/100000 | Win Rate: 28.13% | Avg Reward: -20.43 | ε: 0.010\n",
            "Episode 71000/100000 | Win Rate: 28.16% | Avg Reward: -20.42 | ε: 0.010\n",
            "Episode 72000/100000 | Win Rate: 28.17% | Avg Reward: -20.41 | ε: 0.010\n",
            "Episode 73000/100000 | Win Rate: 28.15% | Avg Reward: -20.41 | ε: 0.010\n",
            "Episode 74000/100000 | Win Rate: 28.18% | Avg Reward: -20.40 | ε: 0.010\n",
            "Episode 75000/100000 | Win Rate: 28.21% | Avg Reward: -20.38 | ε: 0.010\n",
            "Episode 76000/100000 | Win Rate: 28.21% | Avg Reward: -20.38 | ε: 0.010\n",
            "Episode 77000/100000 | Win Rate: 28.21% | Avg Reward: -20.39 | ε: 0.010\n",
            "Episode 78000/100000 | Win Rate: 28.21% | Avg Reward: -20.38 | ε: 0.010\n",
            "Episode 79000/100000 | Win Rate: 28.24% | Avg Reward: -20.37 | ε: 0.010\n",
            "Episode 80000/100000 | Win Rate: 28.27% | Avg Reward: -20.36 | ε: 0.010\n",
            "Episode 81000/100000 | Win Rate: 28.28% | Avg Reward: -20.35 | ε: 0.010\n",
            "Episode 82000/100000 | Win Rate: 28.31% | Avg Reward: -20.34 | ε: 0.010\n",
            "Episode 83000/100000 | Win Rate: 28.33% | Avg Reward: -20.34 | ε: 0.010\n",
            "Episode 84000/100000 | Win Rate: 28.36% | Avg Reward: -20.32 | ε: 0.010\n",
            "Episode 85000/100000 | Win Rate: 28.36% | Avg Reward: -20.32 | ε: 0.010\n",
            "Episode 86000/100000 | Win Rate: 28.37% | Avg Reward: -20.31 | ε: 0.010\n",
            "Episode 87000/100000 | Win Rate: 28.37% | Avg Reward: -20.31 | ε: 0.010\n",
            "Episode 88000/100000 | Win Rate: 28.36% | Avg Reward: -20.32 | ε: 0.010\n",
            "Episode 89000/100000 | Win Rate: 28.40% | Avg Reward: -20.30 | ε: 0.010\n",
            "Episode 90000/100000 | Win Rate: 28.43% | Avg Reward: -20.28 | ε: 0.010\n",
            "Episode 91000/100000 | Win Rate: 28.47% | Avg Reward: -20.26 | ε: 0.010\n",
            "Episode 92000/100000 | Win Rate: 28.46% | Avg Reward: -20.26 | ε: 0.010\n",
            "Episode 93000/100000 | Win Rate: 28.50% | Avg Reward: -20.24 | ε: 0.010\n",
            "Episode 94000/100000 | Win Rate: 28.52% | Avg Reward: -20.23 | ε: 0.010\n",
            "Episode 95000/100000 | Win Rate: 28.52% | Avg Reward: -20.23 | ε: 0.010\n",
            "Episode 96000/100000 | Win Rate: 28.53% | Avg Reward: -20.23 | ε: 0.010\n",
            "Episode 97000/100000 | Win Rate: 28.56% | Avg Reward: -20.21 | ε: 0.010\n",
            "Episode 98000/100000 | Win Rate: 28.59% | Avg Reward: -20.20 | ε: 0.010\n",
            "Episode 99000/100000 | Win Rate: 28.60% | Avg Reward: -20.19 | ε: 0.010\n",
            "Episode 100000/100000 | Win Rate: 28.62% | Avg Reward: -20.18 | ε: 0.010\n",
            "Agent saved → hangman_agent.pkl\n",
            "Training complete! Models saved.\n"
          ]
        }
      ],
      "source": [
        "# CELL 7: Train the System on YOUR Data\n",
        "def load_words(path):\n",
        "    with open(path, 'r') as f:\n",
        "        return [line.strip().lower() for line in f if line.strip() and line.strip().isalpha()]\n",
        "\n",
        "print(\"Loading your corpus...\")\n",
        "words = load_words(\"corpus.txt\")\n",
        "\n",
        "print(f\"Training HMM on {len(words)} words...\")\n",
        "hmm = HangmanHMM(max_length=20)\n",
        "hmm.train(words)\n",
        "hmm.save(\"hangman_hmm.pkl\")\n",
        "\n",
        "print(\"Initializing Q-Learning Agent...\")\n",
        "agent = HangmanQLearningAgent(\n",
        "    hmm=hmm,\n",
        "    learning_rate=0.01,\n",
        "    discount_factor=0.95,\n",
        "    epsilon_start=1.0,\n",
        "    epsilon_end=0.01,\n",
        "    epsilon_decay=0.995\n",
        ")\n",
        "\n",
        "print(\"Starting training (10,000 episodes)...\")\n",
        "eval_every = 1000\n",
        "for ep in range(100000):\n",
        "    word = random.choice(words)\n",
        "    result = agent.train_episode(word)\n",
        "\n",
        "    if (ep + 1) % eval_every == 0:\n",
        "        win_rate = agent.stats['wins'] / agent.stats['episodes']\n",
        "        avg_reward = agent.stats['total_reward'] / agent.stats['episodes']\n",
        "        print(f\"Episode {ep+1}/{100000} | Win Rate: {win_rate:.2%} | Avg Reward: {avg_reward:+.2f} | ε: {agent.epsilon:.3f}\")\n",
        "\n",
        "agent.save(\"hangman_agent.pkl\")\n",
        "print(\"Training complete! Models saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oensDFilW8xv",
        "outputId": "88004000-c7fa-4d04-8ab4-1289f3f2c334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading models for evaluation...\n",
            "HMM loaded from hangman_hmm.pkl\n",
            "Agent loaded ← hangman_agent.pkl\n",
            "Evaluating on 2000 test words...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "Total Games:     2000\n",
            "Wins:            605 (30.25%)\n",
            "Losses:          1395\n",
            "Avg Wrong Guesses: 5.27\n",
            "Final Score:     -5239.75\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# CELL 8: Evaluate on Your Test Set\n",
        "print(\"Loading models for evaluation...\")\n",
        "hmm = HangmanHMM()\n",
        "hmm.load(\"hangman_hmm.pkl\")\n",
        "agent = HangmanQLearningAgent(hmm)\n",
        "agent.load(\"hangman_agent.pkl\")\n",
        "\n",
        "test_words = load_words(\"test.txt\")\n",
        "print(f\"Evaluating on {len(test_words)} test words...\")\n",
        "\n",
        "results = [agent.play(word) for word in test_words]\n",
        "\n",
        "wins = sum(1 for r in results if r['won'])\n",
        "success_rate = wins / len(results)\n",
        "total_wrong = sum(r['wrong'] for r in results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total Games:     {len(results)}\")\n",
        "print(f\"Wins:            {wins} ({success_rate:.2%})\")\n",
        "print(f\"Losses:          {len(results) - wins}\")\n",
        "print(f\"Avg Wrong Guesses: {total_wrong/len(results):.2f}\")\n",
        "print(f\"Final Score:     {success_rate * 100 - total_wrong * 0.5:.2f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
